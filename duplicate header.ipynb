{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87916ff4-cc78-4a6e-a260-91bbac6a5c24",
   "metadata": {},
   "source": [
    "# Duplicate header transformation challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac75b696-99fa-42ad-9db2-860e2d6ebb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from frictionless import Package, Resource, transform, steps, describe, Schema, validate, Dialect, table\n",
    "from tabulate import tabulate\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# https://framework.frictionlessdata.io/docs/guides/validating-data.html#validation-report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e9fffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Schema.describe('Purdue_ACRE_DTC_2021_1_1.csv')\n",
    "schema.to_yaml(\"harvest.schema.yaml\")\n",
    "\n",
    "df='Purdue_ACRE_DTC_2021_1_1.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806891df",
   "metadata": {},
   "source": [
    "### Using pandas to open file\n",
    "In Pandas, Duplicate fields are read as Field and Field.1. I also noticed that pandas dataframe sometimes reads fields with integer type as numpy integer. I was running into errors with this previously but I think frictionless validation does not have problem with this (it reads this as integer type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d786d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv(df, encoding='mbcs')  \n",
    "\n",
    "# Check instance of field\n",
    "print('Product field instance of np.int64:',isinstance(file['Product'][0], np.int64), '...',\n",
    "      'Product field instance of int: ',isinstance(file['Product'][0], int))\n",
    "\n",
    "schema_file = \"harvest.schema2.yaml\"\n",
    "schema_one = Schema.from_descriptor(schema_file) # from a descriptor path\n",
    "\n",
    "try:\n",
    "    report = validate(file, schema=schema_one,limit_errors=1)\n",
    "    # print(report.valid)\n",
    "    if(report.valid == False):\n",
    "        pprint(report)\n",
    "except UnicodeDecodeError as e:\n",
    "    print(f\"Error decoding file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a76423",
   "metadata": {},
   "source": [
    "### Using python's csv library\n",
    "I wrote this custom code to identify a duplicate field using python csv library. The end goal is to transform the files with duplicate fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d976686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_col_files=[]\n",
    "def check_and_update_duplicate_columns(file_path, destination_folder):\n",
    "    with open(file_path, mode='r', newline='', encoding='mbcs') as file:\n",
    "        reader = csv.reader(file)\n",
    "        headers = next(reader)\n",
    "        data = list(reader)\n",
    "\n",
    "    # Check for duplicate columns and update names\n",
    "    seen = {}\n",
    "    new_headers = []\n",
    "    for col in headers:\n",
    "        if col in seen:\n",
    "            seen[col] += 1\n",
    "            new_headers.append(f\"{col}_{seen[col]}\")\n",
    "        else:\n",
    "            seen[col] = 0\n",
    "            new_headers.append(col)\n",
    "\n",
    "    duplicate_columns = [col for col, count in seen.items() if count > 0]\n",
    "\n",
    "    if duplicate_columns:\n",
    "        print(\"Duplicate columns found:\", duplicate_columns)\n",
    "       \n",
    "\n",
    "\n",
    "check_and_update_duplicate_columns(df, 'duplicate_col_folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aafc8ee",
   "metadata": {},
   "source": [
    "### Duplicate header using Frictionless data transform\n",
    "Jarod mentioned that he wants minimal custom code so we can document the pipeline based on Frictionless glossary. So I tried using Frictionless transform\n",
    "\n",
    "In Frictionless, Duplicate fields are read as Field and Field2. The challenge is that I cannot perform any function (move, pack, merge etc) on the duplicate field (Field2) except to remove the field (https://framework.frictionlessdata.io/docs/steps/field.html#remove-field). This means I cannot directly work with Field2 and in someways, Frictionless does not 'identify' it. \n",
    "\n",
    "I used this method on a demo csv file and it worked but it fails when I use on the file from SMS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63042d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = Resource(path=\"harvest/all_harvest/Purdue_ACRE_DTC_2021_1_1.csv\")\n",
    "target = transform(\n",
    "    source,\n",
    "    steps=[\n",
    "\n",
    "        steps.field_merge(name=\"name4\", from_names=[\"Diff Status\"], preserve=False), # Change Field to a temporary name (name4). This automatically changes Field2 to Field\n",
    "\n",
    "        # This step is throwing errors (when you run target.to_view()). I tried it on a demo csv file and it worked\n",
    "        steps.field_add(name=\"name3\", formula='Diff Status*1'), # A new field (name3) is created from the duplicate (now identified as Field) so that Frictionless can identify\n",
    "        \n",
    "        steps.field_remove(names=[\"Diff Status2\"]), # Get rid of the duplicate (now identified as Field)\n",
    "        steps.field_merge(name=\"Diff Status\", from_names=[\"name4\"], preserve=False), # Rename temp field to original name\n",
    "        steps.field_merge(name=\"Diff Status2\", from_names=[\"name3\"], preserve=False), # Rename temp field to original name\n",
    "        steps.field_move(name=\"Diff Status\", position=14), # Move Field back to original position\n",
    "        steps.field_move(name=\"Diff Status2\", position=20), # Move Field back to original position\n",
    "\n",
    "    ]\n",
    ")\n",
    "print(target.schema)\n",
    "print(target.to_view())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f07b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = validate(target, schema=schema,limit_errors=2)\n",
    "if(report.valid == False):\n",
    "    pprint(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
